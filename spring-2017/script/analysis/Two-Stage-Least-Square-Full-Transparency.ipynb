{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61356057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.api import add_constant\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "%store -r perform_dist_high_compare_b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55eb830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Student</th>\n",
       "      <th>group</th>\n",
       "      <th>abs_perform_diff_best</th>\n",
       "      <th>phase</th>\n",
       "      <th>Q7_Q7_1</th>\n",
       "      <th>Q7_Q7_2</th>\n",
       "      <th>Q8_Q8_1</th>\n",
       "      <th>Q10</th>\n",
       "      <th>user2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lemartinp</td>\n",
       "      <td>3</td>\n",
       "      <td>270.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lemartinp</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>juligarji</td>\n",
       "      <td>3</td>\n",
       "      <td>167.50</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>juligarji</td>\n",
       "      <td>0.057325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nfmorenog</td>\n",
       "      <td>3</td>\n",
       "      <td>225.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nfmorenog</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AFelipeGA</td>\n",
       "      <td>3</td>\n",
       "      <td>291.67</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AFelipeGA</td>\n",
       "      <td>0.003841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mballeng91</td>\n",
       "      <td>3</td>\n",
       "      <td>329.17</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mballeng91</td>\n",
       "      <td>0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>NicolasPrr</td>\n",
       "      <td>3</td>\n",
       "      <td>237.50</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NicolasPrr</td>\n",
       "      <td>0.009360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>jumcorredorro</td>\n",
       "      <td>3</td>\n",
       "      <td>53.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>jumcorredorro</td>\n",
       "      <td>0.013294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>feartheGru</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>feartheGru</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>Danielsv9207</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Danielsv9207</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>JhonEmmanuelTorres</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>JhonEmmanuelTorres</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             Student  group  abs_perform_diff_best  phase  \\\n",
       "0             0           lemartinp      3                 270.84      1   \n",
       "1             1           juligarji      3                 167.50      1   \n",
       "2             2           nfmorenog      3                 225.00      1   \n",
       "3             3           AFelipeGA      3                 291.67      1   \n",
       "4             4          mballeng91      3                 329.17      1   \n",
       "..          ...                 ...    ...                    ...    ...   \n",
       "159         159          NicolasPrr      3                 237.50      4   \n",
       "160         160       jumcorredorro      3                  53.33      4   \n",
       "161         161          feartheGru      3                 358.33      4   \n",
       "162         162        Danielsv9207      3                 358.33      4   \n",
       "163         163  JhonEmmanuelTorres      3                 358.33      4   \n",
       "\n",
       "     Q7_Q7_1  Q7_Q7_2  Q8_Q8_1  Q10               user2  similarity  \n",
       "0        0.0      0.0      4.0  1.0           lemartinp    0.146341  \n",
       "1        4.0      4.0      5.0  3.0           juligarji    0.057325  \n",
       "2        0.0      2.0      3.0  1.0           nfmorenog    0.190476  \n",
       "3        4.0      3.0      5.0  2.0           AFelipeGA    0.003841  \n",
       "4        2.0      6.0      6.0  2.0          mballeng91    0.004854  \n",
       "..       ...      ...      ...  ...                 ...         ...  \n",
       "159      3.0      4.0      3.0  2.0          NicolasPrr    0.009360  \n",
       "160      1.0      1.0      5.0  2.0       jumcorredorro    0.013294  \n",
       "161      2.0      2.0      5.0  2.0          feartheGru    0.000000  \n",
       "162      1.0      1.0      1.0  3.0        Danielsv9207    0.000000  \n",
       "163      5.0      4.0      5.0  2.0  JhonEmmanuelTorres    0.000000  \n",
       "\n",
       "[160 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('perform_dist_high_compare_b3.csv', header=0)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d9ca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     abs_perform_diff_best   R-squared:                       0.086\n",
      "Model:                               OLS   Adj. R-squared:                  0.080\n",
      "Method:                    Least Squares   F-statistic:                     14.87\n",
      "Date:                   Mon, 12 Sep 2022   Prob (F-statistic):           0.000167\n",
      "Time:                           00:16:24   Log-Likelihood:                -913.78\n",
      "No. Observations:                    160   AIC:                             1832.\n",
      "Df Residuals:                        158   BIC:                             1838.\n",
      "Df Model:                              1                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    258.9941     15.856     16.334      0.000     227.678     290.311\n",
      "Q10          -30.3360      7.867     -3.856      0.000     -45.873     -14.799\n",
      "==============================================================================\n",
      "Omnibus:                        0.652   Durbin-Watson:                   1.534\n",
      "Prob(Omnibus):                  0.722   Jarque-Bera (JB):                0.319\n",
      "Skew:                          -0.019   Prob(JB):                        0.853\n",
      "Kurtosis:                       3.215   Cond. No.                         6.70\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          ln_similarity   R-squared:                       0.045\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.039\n",
      "Method:                     Two Stage   F-statistic:                    0.1466\n",
      "                        Least Squares   Prob (F-statistic):              0.702\n",
      "Date:                Mon, 12 Sep 2022                                         \n",
      "Time:                        00:16:25                                         \n",
      "No. Observations:                 160                                         \n",
      "Df Residuals:                     158                                         \n",
      "Df Model:                           1                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     0.0735      0.039      1.908      0.058      -0.003       0.150\n",
      "abs_perform_diff_best -7.251e-05      0.000     -0.383      0.702      -0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                       13.088   Durbin-Watson:                   1.207\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.128\n",
      "Skew:                           0.698   Prob(JB):                     0.000855\n",
      "Kurtosis:                       2.589   Cond. No.                         611.\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          ln_similarity   R-squared:                       0.075\n",
      "Model:                            OLS   Adj. R-squared:                  0.069\n",
      "Method:                 Least Squares   F-statistic:                     12.81\n",
      "Date:                Mon, 12 Sep 2022   Prob (F-statistic):           0.000457\n",
      "Time:                        00:16:25   Log-Likelihood:                 244.29\n",
      "No. Observations:                 160   AIC:                            -484.6\n",
      "Df Residuals:                     158   BIC:                            -478.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0984      0.012      8.327      0.000       0.075       0.122\n",
      "abs_perform_diff_best    -0.0002   5.47e-05     -3.580      0.000      -0.000   -8.77e-05\n",
      "==============================================================================\n",
      "Omnibus:                       10.169   Durbin-Watson:                   1.191\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):               10.965\n",
      "Skew:                           0.626   Prob(JB):                      0.00416\n",
      "Kurtosis:                       2.725   Cond. No.                         611.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Let's confirm that aspiration satisfy the relevance condition for performance distance to the best \n",
    "reg_expr = 'abs_perform_diff_best ~ Q10'\n",
    "\n",
    "# Build and train an OLS model that regresses performance distance to the best on aspiration and verify\n",
    "# using the F-test that coefficients of aspiration is significant \n",
    "olsr_model = smf.ols(formula=reg_expr, data=df)\n",
    "olsr_model_results = olsr_model.fit()\n",
    "print(olsr_model_results.summary())\n",
    "\n",
    "df['ln_similarity'] = np.log(df['similarity'] + 1)\n",
    "\n",
    "# Build out the exog matrix. Statsmodels requires this matrix to contain all the endogenous and\n",
    "# exogenous variables, plus the constant.\n",
    "exog = df[['abs_perform_diff_best']]\n",
    "exog = add_constant(exog)\n",
    "\n",
    "# Build out the instruments matrix. Statsmodels requires this matrix to contain not only all the\n",
    "# instruments but also the variables in exog that will NOT be instrumented\n",
    "instruments = df[['Q10']]\n",
    "instruments = add_constant(instruments)\n",
    "\n",
    "#Build and train the IV2SLS model\n",
    "iv2sls_model = IV2SLS(endog=df['ln_similarity'], exog=exog, instrument=instruments)\n",
    "iv2sls_model_results = iv2sls_model.fit()\n",
    "\n",
    "#Print the training summary\n",
    "print(iv2sls_model_results.summary())\n",
    "\n",
    "#Compare the performance of 2SLS with OLS of ln(wage) on performance distance to the best\n",
    "reg_expr = 'ln_similarity ~ abs_perform_diff_best'\n",
    "olsr_model = smf.ols(formula=reg_expr, data=df)\n",
    "olsr_model_results = olsr_model.fit()\n",
    "print(olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816cff2",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0da5ae",
   "metadata": {},
   "source": [
    "![image1a](image1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf987c",
   "metadata": {},
   "source": [
    "The coefficients of aspiration (Q10) is significant at a p of < 0 as indicated by their p-values which are basically zero. Aspiration (Q10) clearly meet the **relevance condition** for instrumental variables of performance distance. \n",
    "\n",
    "We’ll now build a linear model for the similarity to the best equation and using statsmodels, we’ll train the model using the two-stage least square estimator.\n",
    "\n",
    "We’ll start by building the design matrices. The dependent variable is ln(similarity). \n",
    "\n",
    "```\n",
    "ln_wage = np.log(df['similarity'])\n",
    "```\n",
    "\n",
    "Statsmodel’s IV2SLS estimator is defined as follows:\n",
    "\n",
    "```\n",
    "\n",
    "statsmodels.sandbox.regression.gmm.IV2SLS(endog, exog, instrument=None)\n",
    "\n",
    "```\n",
    "Statsmodels needs the endog, exog and instrument matrices to be constructed in a specific way as follows:\n",
    "\n",
    "`endog` is an [n x 1] matrix containing the dependent variable. In our example, it is the log(similarity) variable.\n",
    "\n",
    "`exog` is an [n x (k+1)] size matrix that must contain all the endogenous and exogenous variables, plus the constant. In our example, apart from the constant, we do not have any exogenous variables defined in our wage equation. \n",
    "\n",
    "`instrument` is a matrix that contains the instrumental variables. Additionally, the Statsmodels’ IV2SLS estimator requires instrument to also contain all variables from the exog matrix that are not being instrumented. In our example, the instrumental variable is aspiration. The variables in exog that are not being instrumented is just the placeholder column for the intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e56287",
   "metadata": {},
   "source": [
    "![image2a](image2a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2aa2cf",
   "metadata": {},
   "source": [
    "## Interpretation of results of the 2SLS model\n",
    "\n",
    "Since our primary interest is in estimating the effect of performance distance to the best on similarity to the best, we’ll focus our attention on the coefficient estimate of the performance distance to the best. \n",
    "\n",
    "We see that the 2SLS model has estimated the coefficient of performance distance to the best as -7.251e-05 with a standard error of 0.000 and a 95% confidence interval of -0.000 to 0.000. The p-value of 0.084 suggests a significance at (1–0.702)100%=29.8%. Overall, and as expected for a 2SLS model, the model lacks precision.\n",
    "\n",
    "Note that dependent variable is log(similarity + 1). To calculate the rate of change of similarity to the best for each unit change of performance distance to the best, we must exponentiate the coefficient of performance distance to the best.\n",
    "\n",
    "1 - 10^(-7.251e-05) = 0.000167 implying that a unit decrease in performance distance to the best is estimated to yield an increase of 0.000167 in similarity to the best, and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd5794b",
   "metadata": {},
   "source": [
    "## Comparison of the IV estimator with an OLS estimator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baa040",
   "metadata": {},
   "source": [
    "Let’s compare the performance of the 2SLS model with a straight-up OLS model that regresses log(similarity) on performance distance to the best. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cf0fc0d",
   "metadata": {},
   "source": [
    "![image3a.png](image3a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06eb8e",
   "metadata": {},
   "source": [
    "We’ll focus our attention on the estimated value of the coefficient of performance distance to the best. At -0.0002, it is a lot higher than the estimate reported by the 2SLS model.\n",
    "\n",
    "1 - 10^(-0.0002)=0.00046, implying a unit decrease in the performance distance to the best is estimated to translate into a 0.00046 increase in similarity to the best (vice versa). \n",
    "\n",
    "The higher estimate from OLS is expected due to the suspected endogeniety of performance distance to the best. In practice, depending on the situation we are modeling, we may want to accept the more conservative estimate of -7.251e-05 reported by the 2SLS model. However, (and against the 2SLS model), the coefficient estimate from the OLS model is highly significant with a p-value that is 0.000. Recollect that the estimate from the 2SLS model was significant at only a 29.8% confidence level.\n",
    "\n",
    "The coefficient estimate of performance distance to the best reported by the OLS model has pretty similar standard error which is zero as compared to that from the 2SLS model. \n",
    "\n",
    "For comparison, here are the coefficient estimates of performance distance to the best and corresponding 95% CIs from the two models:\n",
    "\n",
    "With the IV estimator, one trades precision of estimates for the removal of endogeneity and the consequent bias in the estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4b679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

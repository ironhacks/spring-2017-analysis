{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392bfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.api import add_constant\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "%store -r full\n",
    "%store -r solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0467ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Student</th>\n",
       "      <th>group</th>\n",
       "      <th>abs_perform_diff_best</th>\n",
       "      <th>phase</th>\n",
       "      <th>Q7_Q7_1</th>\n",
       "      <th>Q7_Q7_2</th>\n",
       "      <th>Q8_Q8_1</th>\n",
       "      <th>Q10</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ln_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lemartinp</td>\n",
       "      <td>3</td>\n",
       "      <td>270.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.136576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>juligarji</td>\n",
       "      <td>3</td>\n",
       "      <td>167.50</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.055742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nfmorenog</td>\n",
       "      <td>3</td>\n",
       "      <td>225.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.174353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AFelipeGA</td>\n",
       "      <td>3</td>\n",
       "      <td>291.67</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.087011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mballeng91</td>\n",
       "      <td>3</td>\n",
       "      <td>329.17</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>NicolasPrr</td>\n",
       "      <td>3</td>\n",
       "      <td>237.50</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>0.009316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>jumcorredorro</td>\n",
       "      <td>3</td>\n",
       "      <td>53.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>0.013206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>feartheGru</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>Danielsv9207</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>JhonEmmanuelTorres</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             Student  group  abs_perform_diff_best  phase  \\\n",
       "0             0           lemartinp      3                 270.84      1   \n",
       "1             1           juligarji      3                 167.50      1   \n",
       "2             2           nfmorenog      3                 225.00      1   \n",
       "3             3           AFelipeGA      3                 291.67      1   \n",
       "4             4          mballeng91      3                 329.17      1   \n",
       "..          ...                 ...    ...                    ...    ...   \n",
       "159         159          NicolasPrr      3                 237.50      4   \n",
       "160         160       jumcorredorro      3                  53.33      4   \n",
       "161         161          feartheGru      3                 358.33      4   \n",
       "162         162        Danielsv9207      3                 358.33      4   \n",
       "163         163  JhonEmmanuelTorres      3                 358.33      4   \n",
       "\n",
       "     Q7_Q7_1  Q7_Q7_2  Q8_Q8_1  Q10  similarity  ln_similarity  \n",
       "0        0.0      0.0      4.0  1.0    0.146341       0.136576  \n",
       "1        4.0      4.0      5.0  3.0    0.057325       0.055742  \n",
       "2        0.0      2.0      3.0  1.0    0.190476       0.174353  \n",
       "3        4.0      3.0      5.0  2.0    0.090909       0.087011  \n",
       "4        2.0      6.0      6.0  2.0    0.004854       0.004843  \n",
       "..       ...      ...      ...  ...         ...            ...  \n",
       "159      3.0      4.0      3.0  2.0    0.009360       0.009316  \n",
       "160      1.0      1.0      5.0  2.0    0.013294       0.013206  \n",
       "161      2.0      2.0      5.0  2.0    0.000000       0.000000  \n",
       "162      1.0      1.0      1.0  3.0    0.000000       0.000000  \n",
       "163      5.0      4.0      5.0  2.0    0.000000       0.000000  \n",
       "\n",
       "[160 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3532a8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Student</th>\n",
       "      <th>group</th>\n",
       "      <th>abs_perform_diff_best</th>\n",
       "      <th>phase</th>\n",
       "      <th>Q7_Q7_1</th>\n",
       "      <th>Q7_Q7_2</th>\n",
       "      <th>Q8_Q8_1</th>\n",
       "      <th>Q10</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ln_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bdvegat</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>0.052770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Phoenixest</td>\n",
       "      <td>2</td>\n",
       "      <td>185.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.017805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HashNick</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.023420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ccvacad</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>joaortizro</td>\n",
       "      <td>2</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.040585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>162</td>\n",
       "      <td>lsfinite</td>\n",
       "      <td>2</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>xdanielsb</td>\n",
       "      <td>2</td>\n",
       "      <td>283.33</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.039344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>CSebasGomez</td>\n",
       "      <td>2</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>jhcardenasa</td>\n",
       "      <td>2</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.049762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>jscontrerasp</td>\n",
       "      <td>2</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054455</td>\n",
       "      <td>0.053024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       Student  group  abs_perform_diff_best  phase  Q7_Q7_1  \\\n",
       "1             1       bdvegat      2                 260.00      1      1.0   \n",
       "2             2    Phoenixest      2                 185.83      1      0.0   \n",
       "3             3      HashNick      2                 260.00      1      1.0   \n",
       "4             4       ccvacad      2                 260.00      1      1.0   \n",
       "5             5    joaortizro      2                 152.50      1      0.0   \n",
       "..          ...           ...    ...                    ...    ...      ...   \n",
       "162         162      lsfinite      2                 358.33      4      1.0   \n",
       "163         163     xdanielsb      2                 283.33      4      3.0   \n",
       "164         164   CSebasGomez      2                 358.33      4      3.0   \n",
       "165         165   jhcardenasa      2                 358.33      4      4.0   \n",
       "167         167  jscontrerasp      2                 358.33      4      1.0   \n",
       "\n",
       "     Q7_Q7_2  Q8_Q8_1  Q10  similarity  ln_similarity  \n",
       "1        2.0      4.0  1.0    0.054187       0.052770  \n",
       "2        1.0      3.0  1.0    0.017964       0.017805  \n",
       "3        3.0      5.0  3.0    0.023697       0.023420  \n",
       "4        0.0      4.0  2.0    0.000000       0.000000  \n",
       "5        2.0      2.0  1.0    0.041420       0.040585  \n",
       "..       ...      ...  ...         ...            ...  \n",
       "162      1.0      6.0  3.0    0.008392       0.008357  \n",
       "163      3.0      3.0  2.0    0.040128       0.039344  \n",
       "164      3.0      5.0  2.0    0.000000       0.000000  \n",
       "165      4.0      5.0  3.0    0.051020       0.049762  \n",
       "167      1.0      4.0  0.0    0.054455       0.053024  \n",
       "\n",
       "[156 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995184ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Student</th>\n",
       "      <th>group</th>\n",
       "      <th>abs_perform_diff_best</th>\n",
       "      <th>phase</th>\n",
       "      <th>Q7_Q7_1</th>\n",
       "      <th>Q7_Q7_2</th>\n",
       "      <th>Q8_Q8_1</th>\n",
       "      <th>Q10</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ln_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bdvegat</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>0.052770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Phoenixest</td>\n",
       "      <td>2</td>\n",
       "      <td>185.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.017805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HashNick</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.023420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ccvacad</td>\n",
       "      <td>2</td>\n",
       "      <td>260.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>joaortizro</td>\n",
       "      <td>2</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.040585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>159</td>\n",
       "      <td>NicolasPrr</td>\n",
       "      <td>3</td>\n",
       "      <td>237.50</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>0.009316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>160</td>\n",
       "      <td>jumcorredorro</td>\n",
       "      <td>3</td>\n",
       "      <td>53.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>0.013206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>161</td>\n",
       "      <td>feartheGru</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>162</td>\n",
       "      <td>Danielsv9207</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>163</td>\n",
       "      <td>JhonEmmanuelTorres</td>\n",
       "      <td>3</td>\n",
       "      <td>358.33</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             Student  group  abs_perform_diff_best  phase  \\\n",
       "0             1             bdvegat      2                 260.00      1   \n",
       "1             2          Phoenixest      2                 185.83      1   \n",
       "2             3            HashNick      2                 260.00      1   \n",
       "3             4             ccvacad      2                 260.00      1   \n",
       "4             5          joaortizro      2                 152.50      1   \n",
       "..          ...                 ...    ...                    ...    ...   \n",
       "311         159          NicolasPrr      3                 237.50      4   \n",
       "312         160       jumcorredorro      3                  53.33      4   \n",
       "313         161          feartheGru      3                 358.33      4   \n",
       "314         162        Danielsv9207      3                 358.33      4   \n",
       "315         163  JhonEmmanuelTorres      3                 358.33      4   \n",
       "\n",
       "     Q7_Q7_1  Q7_Q7_2  Q8_Q8_1  Q10  similarity  ln_similarity  \n",
       "0        1.0      2.0      4.0  1.0    0.054187       0.052770  \n",
       "1        0.0      1.0      3.0  1.0    0.017964       0.017805  \n",
       "2        1.0      3.0      5.0  3.0    0.023697       0.023420  \n",
       "3        1.0      0.0      4.0  2.0    0.000000       0.000000  \n",
       "4        0.0      2.0      2.0  1.0    0.041420       0.040585  \n",
       "..       ...      ...      ...  ...         ...            ...  \n",
       "311      3.0      4.0      3.0  2.0    0.009360       0.009316  \n",
       "312      1.0      1.0      5.0  2.0    0.013294       0.013206  \n",
       "313      2.0      2.0      5.0  2.0    0.000000       0.000000  \n",
       "314      1.0      1.0      1.0  3.0    0.000000       0.000000  \n",
       "315      5.0      4.0      5.0  2.0    0.000000       0.000000  \n",
       "\n",
       "[316 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = solution.append(full, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2943e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                             \n",
      "=================================================================================\n",
      "Dep. Variable:     abs_perform_diff_best   R-squared:                       0.004\n",
      "Model:                               OLS   Adj. R-squared:                  0.001\n",
      "Method:                    Least Squares   F-statistic:                     1.257\n",
      "Date:                   Fri, 16 Sep 2022   Prob (F-statistic):              0.263\n",
      "Time:                           22:05:10   Log-Likelihood:                -1837.9\n",
      "No. Observations:                    316   AIC:                             3680.\n",
      "Df Residuals:                        314   BIC:                             3687.\n",
      "Df Model:                              1                                         \n",
      "Covariance Type:               nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    171.2773     23.431      7.310      0.000     125.177     217.378\n",
      "group         10.2789      9.168      1.121      0.263      -7.759      28.317\n",
      "==============================================================================\n",
      "Omnibus:                        5.267   Durbin-Watson:                   1.384\n",
      "Prob(Omnibus):                  0.072   Jarque-Bera (JB):                4.296\n",
      "Skew:                          -0.188   Prob(JB):                        0.117\n",
      "Kurtosis:                       2.571   Cond. No.                         15.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:          ln_similarity   R-squared:                      -7.028\n",
      "Model:                         IV2SLS   Adj. R-squared:                 -7.053\n",
      "Method:                     Two Stage   F-statistic:                    0.9672\n",
      "                        Least Squares   Prob (F-statistic):              0.326\n",
      "Date:                Fri, 16 Sep 2022                                         \n",
      "Time:                        22:05:10                                         \n",
      "No. Observations:                 316                                         \n",
      "Df Residuals:                     314                                         \n",
      "Df Model:                           1                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    -0.2405      0.301     -0.800      0.424      -0.832       0.351\n",
      "abs_perform_diff_best     0.0015      0.002      0.983      0.326      -0.002       0.005\n",
      "==============================================================================\n",
      "Omnibus:                        2.180   Durbin-Watson:                   1.426\n",
      "Prob(Omnibus):                  0.336   Jarque-Bera (JB):                1.853\n",
      "Skew:                           0.058   Prob(JB):                        0.396\n",
      "Kurtosis:                       2.643   Cond. No.                         558.\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          ln_similarity   R-squared:                       0.056\n",
      "Model:                            OLS   Adj. R-squared:                  0.050\n",
      "Method:                 Least Squares   F-statistic:                     9.248\n",
      "Date:                Fri, 16 Sep 2022   Prob (F-statistic):           0.000125\n",
      "Time:                        22:05:10   Log-Likelihood:                 513.52\n",
      "No. Observations:                 316   AIC:                            -1021.\n",
      "Df Residuals:                     313   BIC:                            -1010.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0347      0.015      2.329      0.020       0.005       0.064\n",
      "abs_perform_diff_best    -0.0001   3.32e-05     -3.209      0.001      -0.000   -4.12e-05\n",
      "group                     0.0165      0.005      3.060      0.002       0.006       0.027\n",
      "==============================================================================\n",
      "Omnibus:                       45.387   Durbin-Watson:                   1.269\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               64.260\n",
      "Skew:                           0.931   Prob(JB):                     1.11e-14\n",
      "Kurtosis:                       4.188   Cond. No.                     1.24e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.24e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Let's confirm that aspiration satisfy the relevance condition for performance distance to the best. There is a difference between aspiration and social aspiration. \n",
    "reg_expr = 'abs_perform_diff_best ~ group'\n",
    "\n",
    "# Build and train an OLS model that regresses performance distance to the best on aspiration and verify\n",
    "# using the F-test that coefficients of aspiration is significant \n",
    "olsr_model = smf.ols(formula=reg_expr, data=df)\n",
    "olsr_model_results = olsr_model.fit()\n",
    "print(olsr_model_results.summary())\n",
    "\n",
    "df['ln_similarity'] = np.log(df['similarity'] + 1)\n",
    "\n",
    "# Build out the exog matrix. Statsmodels requires this matrix to contain all the endogenous and\n",
    "# exogenous variables, plus the constant.\n",
    "exog = df[['abs_perform_diff_best']]\n",
    "exog = add_constant(exog)\n",
    "\n",
    "# Build out the instruments matrix. Statsmodels requires this matrix to contain not only all the\n",
    "# instruments but also the variables in exog that will NOT be instrumented\n",
    "instruments = df[['group']]\n",
    "instruments = add_constant(instruments)\n",
    "\n",
    "#Build and train the IV2SLS model\n",
    "iv2sls_model = IV2SLS(endog=df['ln_similarity'], exog=exog, instrument=instruments)\n",
    "iv2sls_model_results = iv2sls_model.fit()\n",
    "\n",
    "#Print the training summary\n",
    "print(iv2sls_model_results.summary())\n",
    "\n",
    "#Compare the performance of 2SLS with OLS of ln(wage) on performance distance to the best\n",
    "reg_expr = 'ln_similarity ~ abs_perform_diff_best + group'\n",
    "olsr_model = smf.ols(formula=reg_expr, data=df)\n",
    "olsr_model_results = olsr_model.fit()\n",
    "print(olsr_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9027f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
